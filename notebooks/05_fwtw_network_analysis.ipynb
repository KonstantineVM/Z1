{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Cross-Validation with Z1 Aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate FWTW network-implied flows against Z1 aggregates\n",
    "if z1_data is not None and financial_series:\n",
    "    # Calculate implied total financial sector flows from network\n",
    "    network_implied_flows = pd.DataFrame(index=sorted(quarterly_networks.keys()))\n",
    "    \n",
    "    for date, G in quarterly_networks.items():\n",
    "        # Sum all edge weights (total flows)\n",
    "        total_flow = sum(d.get('weight', 0) for _, _, d in G.edges(data=True))\n",
    "        \n",
    "        # Count active relationships\n",
    "        active_relationships = G.number_of_edges()\n",
    "        \n",
    "        # Average flow per relationship\n",
    "        avg_flow = total_flow / active_relationships if active_relationships > 0 else 0\n",
    "        \n",
    "        network_implied_flows.loc[date, 'Total_Flow'] = total_flow\n",
    "        network_implied_flows.loc[date, 'Active_Relationships'] = active_relationships\n",
    "        network_implied_flows.loc[date, 'Avg_Flow_Per_Relationship'] = avg_flow\n",
    "    \n",
    "    # Create validation plots\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Plot 1: Network-implied flows\n",
    "    ax1 = axes[0]\n",
    "    ax1.bar(network_implied_flows.index, \n",
    "            network_implied_flows['Total_Flow'] / 1e12,\n",
    "            width=80, alpha=0.7, label='FWTW Network Total Flows')\n",
    "    ax1.set_ylabel('Total Flows (Trillions $)', fontsize=12)\n",
    "    ax1.set_title('Network-Implied Financial Flows', fontsize=14)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    # Plot 2: Relationship intensity\n",
    "    ax2 = axes[1]\n",
    "    ax2_twin = ax2.twinx()\n",
    "    \n",
    "    l1 = ax2.plot(network_implied_flows.index, \n",
    "                  network_implied_flows['Active_Relationships'],\n",
    "                  'b-', marker='o', linewidth=2, label='Active Relationships')\n",
    "    l2 = ax2_twin.plot(network_implied_flows.index,\n",
    "                       network_implied_flows['Avg_Flow_Per_Relationship'] / 1e9,\n",
    "                       'r--', marker='s', linewidth=2, label='Avg Flow per Relationship')\n",
    "    \n",
    "    ax2.set_ylabel('Number of Active Relationships', color='b', fontsize=12)\n",
    "    ax2_twin.set_ylabel('Avg Flow per Relationship (Billions $)', color='r', fontsize=12)\n",
    "    ax2.tick_params(axis='y', labelcolor='b')\n",
    "    ax2_twin.tick_params(axis='y', labelcolor='r')\n",
    "    ax2.set_xlabel('Date', fontsize=12)\n",
    "    ax2.set_title('Financial Network Relationship Dynamics', fontsize=14)\n",
    "    \n",
    "    lines = l1 + l2\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax2.legend(lines, labels, loc='best')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nNetwork Flow Validation Summary:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Average quarterly total flow: ${network_implied_flows['Total_Flow'].mean()/1e12:.2f}T\")\n",
    "    print(f\"Flow volatility (std): ${network_implied_flows['Total_Flow'].std()/1e12:.2f}T\")\n",
    "    print(f\"Average active relationships: {network_implied_flows['Active_Relationships'].mean():.0f}\")\n",
    "    print(f\"Relationship growth rate: {(network_implied_flows['Active_Relationships'].iloc[-1] / network_implied_flows['Active_Relationships'].iloc[0] - 1)*100:.1f}%\")"
    "## 10. Sector Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sector-level network for visualization\n",
    "sector_network = nx.DiGraph()\n",
    "\n",
    "# Add nodes for each sector\n",
    "for sector in sector_flows.index:\n",
    "    sector_network.add_node(sector, \n",
    "                           total_flow=sector_totals.loc[sector, 'Total_Flow'],\n",
    "                           net_position=sector_totals.loc[sector, 'Net_Position'])\n",
    "\n",
    "# Add edges with flow amounts\n",
    "for holder_sector in sector_flows.index:\n",
    "    for issuer_sector in sector_flows.columns:\n",
    "        flow_amount = sector_flows.loc[holder_sector, issuer_sector]\n",
    "        if flow_amount > 0:\n",
    "            sector_network.add_edge(holder_sector, issuer_sector, weight=flow_amount)\n",
    "\n",
    "# Visualize sector network\n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = nx.circular_layout(sector_network)\n",
    "\n",
    "# Node sizes based on total flow\n",
    "node_sizes = [sector_network.nodes[node]['total_flow'] / 1e8 for node in sector_network.nodes()]\n",
    "\n",
    "# Node colors based on net position\n",
    "node_colors = [sector_network.nodes[node]['net_position'] for node in sector_network.nodes()]\n",
    "\n",
    "# Draw nodes\n",
    "nx.draw_networkx_nodes(sector_network, pos,\n",
    "                      node_size=node_sizes,\n",
    "                      node_color=node_colors,\n",
    "                      cmap='RdBu_r',\n",
    "                      alpha=0.8,\n",
    "                      linewidths=2,\n",
    "                      edgecolors='black')\n",
    "\n",
    "# Draw edges with varying widths\n",
    "edges = sector_network.edges()\n",
    "weights = [sector_network[u][v]['weight'] / 1e9 for u, v in edges]\n",
    "\n",
    "# Use curved edges for better visibility\n",
    "nx.draw_networkx_edges(sector_network, pos,\n",
    "                      width=weights,\n",
    "                      alpha=0.6,\n",
    "                      edge_color='gray',\n",
    "                      arrows=True,\n",
    "                      arrowsize=20,\n",
    "                      connectionstyle='arc3,rad=0.1',\n",
    "                      min_target_margin=15)\n",
    "\n",
    "# Add labels\n",
    "nx.draw_networkx_labels(sector_network, pos, font_size=12, font_weight='bold')\n",
    "\n",
    "# Add edge labels for significant flows\n",
    "edge_labels = {}\n",
    "for u, v, d in sector_network.edges(data=True):\n",
    "    if d['weight'] > 1e10:  # Only show flows > $10B\n",
    "        edge_labels[(u, v)] = f\"${d['weight']/1e9:.0f}B\"\n",
    "\n",
    "nx.draw_networkx_edge_labels(sector_network, pos, edge_labels, font_size=8)\n",
    "\n",
    "plt.title('Sector-Level Financial Network', fontsize=16, pad=20)\n",
    "plt.axis('off')\n",
    "\n",
    "# Add colorbar for net position\n",
    "sm = plt.cm.ScalarMappable(cmap='RdBu_r', \n",
    "                           norm=plt.Normalize(vmin=min(node_colors), \n",
    "                                            vmax=max(node_colors)))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=plt.gca(), orientation='horizontal', \n",
    "                   fraction=0.046, pad=0.1)\n",
    "cbar.set_label('Net Position ($)', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
    "# Flow of Funds Through Wall Street (FWTW) Network Analysis\n",
    "\n",
    "This notebook demonstrates network analysis of financial institution interconnections using FWTW data integrated with Z1 time series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Project imports\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "\n",
    "from src.data.cached_fed_data_loader import CachedFedDataLoader\n",
    "from src.network.fwtw_data_loader import FWTWDataLoader\n",
    "from src.network.network_builder import NetworkBuilder\n",
    "from src.network.network_analyzer import NetworkAnalyzer\n",
    "from src.analysis.economic_analysis import EconomicAnalysis\n",
    "from src.visualization.economic_plots import EconomicVisualizer\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load FWTW Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FWTW data loader\n",
    "fwtw_loader = FWTWDataLoader(cache_dir=\"../data/cache/fwtw\")\n",
    "\n",
    "# Load FWTW data (will use cache if available)\n",
    "print(\"Loading FWTW data...\")\n",
    "fwtw_data = fwtw_loader.load_fwtw_data(force_download=False)\n",
    "\n",
    "if fwtw_data is not None:\n",
    "    print(f\"\\nLoaded {len(fwtw_data):,} records\")\n",
    "    print(f\"Date range: {fwtw_data['Date'].min()} to {fwtw_data['Date'].max()}\")\n",
    "    print(f\"Unique holders: {fwtw_data['Holder Name'].nunique():,}\")\n",
    "    print(f\"Unique issuers: {fwtw_data['Issuer Name'].nunique():,}\")\n",
    "    print(f\"Unique instruments: {fwtw_data['Instrument Name'].nunique():,}\")\n",
    "    \n",
    "    # Display sample data\n",
    "    print(\"\\nSample FWTW data:\")\n",
    "    display(fwtw_data.head())\n",
    "else:\n",
    "    print(\"Failed to load FWTW data. Using simulated data for demonstration...\")\n",
    "    # Create simulated FWTW data for demonstration\n",
    "    np.random.seed(42)\n",
    "    dates = pd.date_range('2020-01-01', '2023-12-31', freq='Q')\n",
    "    institutions = ['Bank A', 'Bank B', 'Bank C', 'Fund X', 'Fund Y', 'Insurance Co']\n",
    "    \n",
    "    fwtw_data = []\n",
    "    for date in dates:\n",
    "        for _ in range(50):\n",
    "            holder = np.random.choice(institutions)\n",
    "            issuer = np.random.choice([i for i in institutions if i != holder])\n",
    "            fwtw_data.append({\n",
    "                'Date': date,\n",
    "                'Holder Name': holder,\n",
    "                'Issuer Name': issuer,\n",
    "                'Amount': np.random.lognormal(10, 2),\n",
    "                'Instrument Name': np.random.choice(['Bond', 'Equity', 'Loan'])\n",
    "            })\n",
    "    \n",
    "    fwtw_data = pd.DataFrame(fwtw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Financial Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize network builder\n",
    "network_builder = NetworkBuilder()\n",
    "\n",
    "# Build networks for each quarter\n",
    "print(\"Building quarterly networks...\")\n",
    "quarterly_networks = {}\n",
    "network_metrics = []\n",
    "\n",
    "for quarter, quarter_data in fwtw_data.groupby(pd.Grouper(key='Date', freq='Q')):\n",
    "    if len(quarter_data) > 0:\n",
    "        # Build network for this quarter\n",
    "        G = network_builder.build_network(quarter_data)\n",
    "        quarterly_networks[quarter] = G\n",
    "        \n",
    "        # Calculate basic metrics\n",
    "        metrics = {\n",
    "            'Date': quarter,\n",
    "            'Nodes': G.number_of_nodes(),\n",
    "            'Edges': G.number_of_edges(),\n",
    "            'Density': nx.density(G),\n",
    "            'Total_Volume': quarter_data['Amount'].sum()\n",
    "        }\n",
    "        network_metrics.append(metrics)\n",
    "\n",
    "network_metrics_df = pd.DataFrame(network_metrics)\n",
    "print(f\"\\nBuilt {len(quarterly_networks)} quarterly networks\")\n",
    "print(\"\\nNetwork metrics summary:\")\n",
    "display(network_metrics_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize network analyzer\n",
    "network_analyzer = NetworkAnalyzer()\n",
    "\n",
    "# Analyze the most recent network\n",
    "latest_date = max(quarterly_networks.keys())\n",
    "latest_network = quarterly_networks[latest_date]\n",
    "\n",
    "print(f\"Analyzing network for {latest_date.strftime('%Y-Q%q')}...\")\n",
    "\n",
    "# Calculate comprehensive centrality measures\n",
    "centrality_measures = {\n",
    "    'degree_centrality': nx.degree_centrality(latest_network),\n",
    "    'in_degree_centrality': nx.in_degree_centrality(latest_network),\n",
    "    'out_degree_centrality': nx.out_degree_centrality(latest_network),\n",
    "    'betweenness_centrality': nx.betweenness_centrality(latest_network, weight='weight'),\n",
    "    'eigenvector_centrality': nx.eigenvector_centrality(latest_network, weight='weight', max_iter=1000),\n",
    "    'pagerank': nx.pagerank(latest_network, weight='weight')\n",
    "}\n",
    "\n",
    "# Create centrality dataframe\n",
    "centrality_df = pd.DataFrame(centrality_measures)\n",
    "centrality_df['entity'] = centrality_df.index\n",
    "\n",
    "# Calculate composite systemic importance score\n",
    "# Normalize each measure to 0-1 scale\n",
    "for col in centrality_measures.keys():\n",
    "    centrality_df[f'{col}_norm'] = (centrality_df[col] - centrality_df[col].min()) / (centrality_df[col].max() - centrality_df[col].min())\n",
    "\n",
    "# Composite score (weighted average)\n",
    "weights = {\n",
    "    'degree_centrality_norm': 0.15,\n",
    "    'betweenness_centrality_norm': 0.25,\n",
    "    'eigenvector_centrality_norm': 0.20,\n",
    "    'pagerank_norm': 0.40\n",
    "}\n",
    "\n",
    "centrality_df['systemic_importance'] = sum(centrality_df[col] * weight \n",
    "                                          for col, weight in weights.items())\n",
    "\n",
    "# Display top institutions by different centrality measures\n",
    "print(\"\\nTop 5 Institutions by Different Centrality Measures:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "measures_to_show = ['pagerank', 'betweenness_centrality', 'eigenvector_centrality', 'systemic_importance']\n",
    "for measure in measures_to_show:\n",
    "    print(f\"\\n{measure.replace('_', ' ').title()}:\")\n",
    "    top_5 = centrality_df.nlargest(5, measure)[['entity', measure]]\n",
    "    for idx, row in top_5.iterrows():\n",
    "        print(f\"  {row['entity'][:50]:<50} {row[measure]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Systemic Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate systemic risk metrics\n",
    "risk_metrics = network_analyzer.calculate_systemic_risk_metrics(latest_network)\n",
    "\n",
    "print(\"Systemic Risk Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Network density: {risk_metrics['density']:.4f}\")\n",
    "print(f\"Herfindahl Index (concentration): {risk_metrics['herfindahl_index']:.4f}\")\n",
    "print(f\"Global efficiency: {risk_metrics['global_efficiency']:.4f}\")\n",
    "print(f\"Average clustering: {risk_metrics['avg_clustering']:.4f}\")\n",
    "print(f\"Assortativity: {risk_metrics['assortativity']:.4f}\")\n",
    "print(f\"Rich club coefficient: {risk_metrics['rich_club_coeff']:.4f}\")\n",
    "\n",
    "# Identify systemically important financial institutions (SIFIs)\n",
    "sifis = network_analyzer.identify_sifis(latest_network, centrality_df)\n",
    "print(f\"\\nSystemically Important Financial Institutions (SIFIs):\")\n",
    "print(\"=\" * 50)\n",
    "for i, (entity, score) in enumerate(sifis[:10], 1):\n",
    "    print(f\"{i}. {entity}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Network Evolution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze network evolution over time\n",
    "evolution_metrics = []\n",
    "\n",
    "for date, G in sorted(quarterly_networks.items()):\n",
    "    # Calculate metrics\n",
    "    metrics = network_analyzer.calculate_systemic_risk_metrics(G)\n",
    "    metrics['Date'] = date\n",
    "    metrics['num_nodes'] = G.number_of_nodes()\n",
    "    metrics['num_edges'] = G.number_of_edges()\n",
    "    evolution_metrics.append(metrics)\n",
    "\n",
    "evolution_df = pd.DataFrame(evolution_metrics)\n",
    "evolution_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Plot network evolution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Network size\n",
    "ax = axes[0, 0]\n",
    "ax.plot(evolution_df.index, evolution_df['num_nodes'], label='Nodes', marker='o')\n",
    "ax.plot(evolution_df.index, evolution_df['num_edges'], label='Edges', marker='s')\n",
    "ax.set_title('Network Size Evolution')\n",
    "ax.set_ylabel('Count')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Density and clustering\n",
    "ax = axes[0, 1]\n",
    "ax.plot(evolution_df.index, evolution_df['density'], label='Density', marker='o')\n",
    "ax.plot(evolution_df.index, evolution_df['avg_clustering'], label='Avg Clustering', marker='s')\n",
    "ax.set_title('Network Connectivity')\n",
    "ax.set_ylabel('Value')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Concentration\n",
    "ax = axes[1, 0]\n",
    "ax.plot(evolution_df.index, evolution_df['herfindahl_index'], color='red', marker='o')\n",
    "ax.set_title('Market Concentration (HHI)')\n",
    "ax.set_ylabel('Herfindahl Index')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Global efficiency\n",
    "ax = axes[1, 1]\n",
    "ax.plot(evolution_df.index, evolution_df['global_efficiency'], color='green', marker='o')\n",
    "ax.set_title('Network Efficiency')\n",
    "ax.set_ylabel('Global Efficiency')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Shock Propagation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced contagion simulation with propagation tracking\n",
    "print(\"Simulating shock propagation scenarios...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Select the most systemically important institution\n",
    "shock_origin = sifis[0][0] if sifis else list(latest_network.nodes())[0]\n",
    "shock_magnitude = 0.15  # 15% shock\n",
    "\n",
    "print(f\"\\nShock scenario: {shock_magnitude:.0%} loss at {shock_origin[:50]}...\")\n",
    "\n",
    "# Initialize shock propagation\n",
    "propagation_history = []\n",
    "current_shocks = {shock_origin: shock_magnitude}\n",
    "all_affected = {shock_origin: shock_magnitude}\n",
    "propagation_threshold = 0.01\n",
    "max_rounds = 10\n",
    "\n",
    "# Propagate shock through network\n",
    "for round_num in range(max_rounds):\n",
    "    new_shocks = {}\n",
    "    \n",
    "    for node, shock in current_shocks.items():\n",
    "        # Propagate to neighbors based on edge weights\n",
    "        total_out = sum(d.get('weight', 0) for _, _, d in latest_network.out_edges(node, data=True))\n",
    "        \n",
    "        if total_out > 0:\n",
    "            for _, neighbor, data in latest_network.out_edges(node, data=True):\n",
    "                weight = data.get('weight', 0)\n",
    "                propagated_shock = shock * (weight / total_out) * 0.5  # 50% pass-through\n",
    "                \n",
    "                if propagated_shock > propagation_threshold:\n",
    "                    if neighbor in new_shocks:\n",
    "                        new_shocks[neighbor] += propagated_shock\n",
    "                    else:\n",
    "                        new_shocks[neighbor] = propagated_shock\n",
    "    \n",
    "    # Update affected nodes\n",
    "    for node, shock in new_shocks.items():\n",
    "        if node in all_affected:\n",
    "            all_affected[node] += shock\n",
    "        else:\n",
    "            all_affected[node] = shock\n",
    "    \n",
    "    propagation_history.append(current_shocks.copy())\n",
    "    \n",
    "    if not new_shocks:\n",
    "        break\n",
    "    \n",
    "    current_shocks = new_shocks\n",
    "\n",
    "# Calculate contagion metrics\n",
    "total_initial_shock = shock_magnitude\n",
    "total_system_shock = sum(all_affected.values())\n",
    "amplification_factor = total_system_shock / total_initial_shock\n",
    "affected_fraction = len(all_affected) / latest_network.number_of_nodes()\n",
    "\n",
    "print(f\"\\nContagion Results:\")\n",
    "print(f\"  Initial shock: {shock_magnitude:.0%}\")\n",
    "print(f\"  Total system impact: {total_system_shock:.2%}\")\n",
    "print(f\"  Amplification factor: {amplification_factor:.2f}x\")\n",
    "print(f\"  Affected institutions: {len(all_affected)} / {latest_network.number_of_nodes()}\")\n",
    "print(f\"  Affected fraction: {affected_fraction:.1%}\")\n",
    "print(f\"  Rounds to convergence: {len(propagation_history)}\")\n",
    "\n",
    "# Visualize shock propagation\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Propagation over rounds\n",
    "rounds = range(len(propagation_history))\n",
    "total_shock_per_round = [sum(shocks.values()) for shocks in propagation_history]\n",
    "cumulative_shock = np.cumsum(total_shock_per_round)\n",
    "\n",
    "ax1.plot(rounds, total_shock_per_round, 'o-', linewidth=2, markersize=8, label='New Shock')\n",
    "ax1.plot(rounds, cumulative_shock, 's--', linewidth=2, markersize=6, label='Cumulative Shock')\n",
    "ax1.set_xlabel('Propagation Round')\n",
    "ax1.set_ylabel('Shock Magnitude')\n",
    "ax1.set_title('Shock Propagation Over Time')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Distribution of final shocks\n",
    "affected_entities = [(entity, shock) for entity, shock in all_affected.items() \n",
    "                    if shock > 0.001]\n",
    "affected_entities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "top_affected = affected_entities[:15]\n",
    "entities = [e[0][:30] + '...' if len(e[0]) > 30 else e[0] for e in top_affected]\n",
    "shocks = [e[1] for e in top_affected]\n",
    "\n",
    "ax2.barh(range(len(entities)), shocks, color=plt.cm.Reds(np.array(shocks)/max(shocks)))\n",
    "ax2.set_yticks(range(len(entities)))\n",
    "ax2.set_yticklabels(entities)\n",
    "ax2.set_xlabel('Shock Magnitude')\n",
    "ax2.set_title('Top 15 Affected Entities')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Network visualization of contagion\n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = nx.spring_layout(latest_network, k=2, iterations=50, seed=42)\n",
    "\n",
    "# Color and size nodes by impact level\n",
    "node_colors = []\n",
    "node_sizes = []\n",
    "for node in latest_network.nodes():\n",
    "    if node == shock_origin:\n",
    "        node_colors.append('red')\n",
    "        node_sizes.append(1000)\n",
    "    elif node in all_affected:\n",
    "        impact = all_affected[node]\n",
    "        if impact > 0.1:\n",
    "            node_colors.append('orangered')\n",
    "            node_sizes.append(700)\n",
    "        elif impact > 0.05:\n",
    "            node_colors.append('orange')\n",
    "            node_sizes.append(500)\n",
    "        else:\n",
    "            node_colors.append('yellow')\n",
    "            node_sizes.append(300)\n",
    "    else:\n",
    "        node_colors.append('lightgray')\n",
    "        node_sizes.append(100)\n",
    "\n",
    "# Draw network\n",
    "nx.draw_networkx_nodes(latest_network, pos, node_color=node_colors, \n",
    "                      node_size=node_sizes, alpha=0.8)\n",
    "nx.draw_networkx_edges(latest_network, pos, alpha=0.2, edge_color='gray')\n",
    "\n",
    "# Add labels for highly affected nodes\n",
    "important_nodes = [shock_origin] + [node for node, shock in affected_entities[:5] if node != shock_origin]\n",
    "labels = {node: node.split()[0] for node in important_nodes}\n",
    "nx.draw_networkx_labels(latest_network, pos, labels, font_size=10, font_weight='bold')\n",
    "\n",
    "plt.title(f'Contagion Spread from {shock_magnitude:.0%} Shock\\nOrigin: {shock_origin[:50]}',\n",
    "          fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='red', label='Shock Origin'),\n",
    "    Patch(facecolor='orangered', label='High Impact (>10%)'),\n",
    "    Patch(facecolor='orange', label='Medium Impact (5-10%)'),\n",
    "    Patch(facecolor='yellow', label='Low Impact (<5%)'),\n",
    "    Patch(facecolor='lightgray', label='Unaffected')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sector Flow Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze flows between different types of institutions\n",
    "# Categorize institutions by type (simplified)\n",
    "def categorize_institution(name):\n",
    "    name_lower = name.lower()\n",
    "    if 'bank' in name_lower:\n",
    "        return 'Banks'\n",
    "    elif 'fund' in name_lower or 'asset' in name_lower:\n",
    "        return 'Asset Managers'\n",
    "    elif 'insurance' in name_lower:\n",
    "        return 'Insurance'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Add sector information\n",
    "latest_data = fwtw_data[fwtw_data['Date'] == latest_date].copy()\n",
    "latest_data['Holder_Sector'] = latest_data['Holder Name'].apply(categorize_institution)\n",
    "latest_data['Issuer_Sector'] = latest_data['Issuer Name'].apply(categorize_institution)\n",
    "\n",
    "# Create sector flow matrix\n",
    "sector_flows = latest_data.groupby(['Holder_Sector', 'Issuer_Sector'])['Amount'].sum().unstack(fill_value=0)\n",
    "\n",
    "# Visualize sector flows\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(sector_flows, annot=True, fmt='.0f', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Total Flow Amount'})\n",
    "plt.title(f'Inter-Sector Financial Flows - {latest_date.strftime(\"%Y-Q%q\")}')\n",
    "plt.xlabel('Issuer Sector')\n",
    "plt.ylabel('Holder Sector')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate net flows\n",
    "net_flows = pd.DataFrame({\n",
    "    'Outflows': sector_flows.sum(axis=1),\n",
    "    'Inflows': sector_flows.sum(axis=0)\n",
    "})\n",
    "net_flows['Net'] = net_flows['Inflows'] - net_flows['Outflows']\n",
    "\n",
    "print(\"\\nNet Sector Flows:\")\n",
    "print(\"=\" * 50)\n",
    "print(net_flows.round(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Integration with Z1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Z1 data for comparison\n",
    "z1_loader = CachedFedDataLoader(\n",
    "    base_directory=\"../data/fed_data\",\n",
    "    cache_directory=\"../data/cache\"\n",
    ")\n",
    "\n",
    "print(\"Loading Z1 data for integration...\")\n",
    "z1_data = z1_loader.load_single_source('Z1')\n",
    "\n",
    "if z1_data is not None:\n",
    "    # Find financial sector series in Z1\n",
    "    financial_series = [col for col in z1_data.columns \n",
    "                       if 'FL7' in col or 'financial' in col.lower()]\n",
    "    \n",
    "    if financial_series:\n",
    "        # Compare network metrics with Z1 financial sector indicators\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "        \n",
    "        # Plot network concentration\n",
    "        ax1 = axes[0]\n",
    "        ax1.plot(evolution_df.index, evolution_df['herfindahl_index'], \n",
    "                'b-', marker='o', label='Network HHI')\n",
    "        ax1.set_ylabel('Herfindahl Index', color='b')\n",
    "        ax1.tick_params(axis='y', labelcolor='b')\n",
    "        ax1.set_title('Network Concentration vs Z1 Financial Sector Growth')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot Z1 financial series on secondary axis\n",
    "        ax2 = ax1.twinx()\n",
    "        z1_financial = z1_data[financial_series[0]].dropna()\n",
    "        # Resample to quarterly if needed\n",
    "        z1_quarterly = z1_financial.resample('Q').last()\n",
    "        z1_growth = z1_quarterly.pct_change(4) * 100  # YoY growth\n",
    "        \n",
    "        ax2.plot(z1_growth.index, z1_growth.values, 'r--', \n",
    "                alpha=0.7, label='Z1 Financial Growth')\n",
    "        ax2.set_ylabel('YoY Growth (%)', color='r')\n",
    "        ax2.tick_params(axis='y', labelcolor='r')\n",
    "        \n",
    "        # Add legends\n",
    "        lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "        \n",
    "        # Plot network efficiency vs market conditions\n",
    "        ax3 = axes[1]\n",
    "        ax3.plot(evolution_df.index, evolution_df['global_efficiency'], \n",
    "                'g-', marker='s', label='Network Efficiency')\n",
    "        ax3.set_ylabel('Global Efficiency')\n",
    "        ax3.set_xlabel('Date')\n",
    "        ax3.set_title('Network Efficiency Over Time')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nCorrelation Analysis:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Calculate correlations if we have overlapping data\n",
    "        common_dates = evolution_df.index.intersection(z1_growth.index)\n",
    "        if len(common_dates) > 10:\n",
    "            corr_hhi = evolution_df.loc[common_dates, 'herfindahl_index'].corr(\n",
    "                z1_growth.loc[common_dates]\n",
    "            )\n",
    "            print(f\"Correlation between network concentration and Z1 financial growth: {corr_hhi:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "print(\"=\" * 60)\n",
    "print(\"FWTW NETWORK ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nData Coverage:\")\n",
    "print(f\"  Period: {fwtw_data['Date'].min()} to {fwtw_data['Date'].max()}\")\n",
    "print(f\"  Total transactions: {len(fwtw_data):,}\")\n",
    "print(f\"  Unique entities: {fwtw_data['Holder Name'].nunique() + fwtw_data['Issuer Name'].nunique()}\")\n",
    "\n",
    "print(f\"\\nNetwork Structure (Latest Quarter):\")\n",
    "print(f\"  Network density: {risk_metrics['density']:.4f}\")\n",
    "print(f\"  Concentration (HHI): {risk_metrics['herfindahl_index']:.4f}\")\n",
    "print(f\"  Global efficiency: {risk_metrics['global_efficiency']:.4f}\")\n",
    "print(f\"  Average clustering: {risk_metrics['avg_clustering']:.4f}\")\n",
    "\n",
    "print(f\"\\nSystemic Risk Indicators:\")\n",
    "print(f\"  Number of SIFIs: {len(sifis)}\")\n",
    "print(f\"  Network assortativity: {risk_metrics['assortativity']:.4f}\")\n",
    "print(f\"  Rich club coefficient: {risk_metrics['rich_club_coeff']:.4f}\")\n",
    "\n",
    "print(f\"\\nContagion Analysis:\")\n",
    "print(f\"  {shock_size:.0%} shock amplification: {contagion_results['amplification_factor']:.2f}x\")\n",
    "print(f\"  System-wide impact: {contagion_results['affected_fraction']:.1%} of nodes affected\")\n",
    "\n",
    "print(\"\\nTop 5 Systemically Important Institutions:\")\n",
    "for i, (entity, score) in enumerate(sifis[:5], 1):\n",
    "    print(f\"  {i}. {entity}\")\n",
    "\n",
    "# Save results\n",
    "output_dir = Path('../data/fwtw_analysis')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save metrics\n",
    "centrality_df.to_csv(output_dir / 'centrality_metrics.csv', index=False)\n",
    "evolution_df.to_csv(output_dir / 'network_evolution.csv')\n",
    "sector_flows.to_csv(output_dir / 'sector_flows_latest.csv')\n",
    "\n",
    "print(f\"\\n Results saved to {output_dir}\")\n",
    "print(\"\\n FWTW network analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
